# AI对话集成实现

## 实现思路

本阶段实现了完整的AI对话集成系统，参考了xiaozhi-server-go的实现，提供了企业级的智能对话解决方案。

## 技术选型

### 核心库
- **标准库**: context, time, sync等Go标准库
- **HTTP客户端**: 用于与AI提供商API通信
- **JSON处理**: encoding/json用于请求和响应解析
- **并发控制**: sync包用于线程安全

### 架构设计
```
plugin/ai/
├── config.go          # 配置管理
├── types.go           # 数据类型和接口定义
├── service.go         # 核心AI服务实现
├── providers.go       # AI提供商实现
├── stub_providers.go  # 占位符提供商
├── cache.go          # 缓存服务实现
├── ai_test.go        # 单元测试
└── README.md          # 使用文档
```

## 核心功能实现

### 1. 配置管理 (config.go)

#### 设计思路
- 支持多种AI提供商的配置
- 提供合理的默认值
- 支持YAML配置文件映射
- 包含成本控制和缓存配置

#### 关键特性
```go
type Config struct {
    // 基础配置
    Enabled      bool
    Provider     string // openai, claude, deepseek, qwen, ollama
    APIKey       string
    BaseURL      string
    Model        string
    
    // 对话配置
    MaxTokens    int
    Temperature  float64
    TopP         float64
    
    // 历史管理
    MaxHistoryLength int
    EnableHistory    bool
    
    // 流式响应
    EnableStreaming bool
    
    // 提供商特定配置
    OpenAI     *OpenAIConfig
    Claude     *ClaudeConfig
    DeepSeek   *DeepSeekConfig
    Qwen       *QwenConfig
    Ollama     *OllamaConfig
}
```

### 2. 类型系统 (types.go)

#### 设计思路
- 定义完整的对话相关数据结构
- 提供灵活的接口和抽象
- 支持流式响应和函数调用
- 包含使用统计和错误信息

#### 核心接口
```go
// AIProvider AI提供商接口
type AIProvider interface {
    Initialize(config *Config) error
    Validate() error
    Chat(ctx context.Context, request *ChatRequest) (*ChatResponse, error)
    ChatStream(ctx context.Context, request *ChatRequest) (<-chan *ChatResponse, error)
    GetModels() []string
    GetModelInfo(model string) (*ModelInfo, error)
    GetUsage(ctx context.Context, startTime, endTime time.Time) (*Usage, error)
    HealthCheck(ctx context.Context) error
}

// AIService AI服务接口
type AIService interface {
    Initialize(config *Config) error
    Start() error
    Stop() error
    IsReady() bool
    
    // 对话管理
    CreateConversation(ctx context.Context, userID string, metadata map[string]interface{}) (*Conversation, error)
    GetConversation(ctx context.Context, conversationID string) (*Conversation, error)
    AddMessage(ctx context.Context, conversationID string, message *Message) error
    
    // 聊天接口
    Chat(ctx context.Context, request *ChatRequest) (*ChatResponse, error)
    ChatStream(ctx context.Context, request *ChatRequest) (<-chan *ChatResponse, error)
    
    // 统计接口
    GetUserStats(ctx context.Context, userID string) (*UserStats, error)
    GetSystemStats(ctx context.Context) (*SystemStats, error)
}
```

### 3. 核心服务 (service.go)

#### 设计思路
- 提供统一的AI服务入口
- 管理对话历史和用户状态
- 支持中间件和插件扩展
- 实现缓存和监控集成

#### 关键功能
```go
type DefaultAIService struct {
    config      *Config
    provider    AIProvider
    cache       CacheService
    metrics     MetricsService
    
    // 对话管理
    conversations map[string]*Conversation
    users        map[string]*UserStats
    
    // 扩展系统
    middlewares []Middleware
    plugins     []Plugin
    
    // 状态管理
    ready   bool
    ctx     context.Context
    cancel  context.CancelFunc
}
```

### 4. 提供商实现 (providers.go)

#### OpenAI提供商
- 完整的OpenAI API集成
- 支持流式和非流式响应
- 实现函数调用能力
- 包含错误处理和重试机制

```go
type OpenAIProvider struct {
    client *http.Client
    config *Config
}

// Chat 聊天接口
func (p *OpenAIProvider) Chat(ctx context.Context, request *ChatRequest) (*ChatResponse, error) {
    // 构建OpenAI API请求
    // 处理错误和重试
    // 解析响应和统计
}
```

#### 其他提供商
- **StubProvider**: 为Claude、DeepSeek、Qwen、Ollama提供占位符实现
- 支持快速扩展新的提供商
- 保持接口一致性

### 5. 缓存系统 (cache.go)

#### 设计思路
- 内存缓存实现，支持TTL和容量限制
- 线程安全的并发访问
- 自动清理过期数据

#### 关键特性
```go
type MemoryCache struct {
    items map[string]*cacheItem
    mu    sync.RWMutex
    config struct {
        TTL     time.Duration
        MaxSize int
    }
}
```

## 高级特性

### 1. 流式响应

实现了完整的流式响应支持，支持实时显示AI回复：

```go
// 启用流式响应
request := &ai.ChatRequest{
    Messages: []ai.Message{
        {Role: "user", Content: "请写一个长篇故事"},
    },
    Stream: true,
}

// 接收流式响应
stream, err := service.ChatStream(ctx, request)
for response := range stream {
    if response.Done {
        break
    }
    if response.Delta != "" {
        fmt.Printf("增量内容: %s\n", response.Delta)
    }
}
```

### 2. 函数调用

支持AI调用外部函数的能力：

```go
// 定义函数
functions := []ai.FunctionDefinition{
    {
        Name: "get_weather",
        Description: "获取指定城市的天气信息",
        Parameters: map[string]interface{}{
            "type": "object",
            "properties": map[string]interface{}{
                "city": map[string]interface{}{
                    "type": "string",
                    "description": "城市名称",
                },
                "units": map[string]interface{}{
                    "type": "string",
                    "enum": []string{"celsius", "fahrenheit"},
                    "description": "温度单位",
                },
            },
            "required": []string{"city"},
        },
    },
}

request := &ai.ChatRequest{
    Messages: []ai.Message{
        {Role: "user", Content: "北京今天天气怎么样？"},
    },
    Functions: functions,
}
```

### 3. 多模态输入

支持文本、图像、音频等多种输入类型：

```go
// 图像输入
message := &ai.Message{
    Role:      "user",
    Content:   "这张图片里有什么？",
    ImageURL:  "https://example.com/image.jpg",
}

// 音频输入
message = &ai.Message{
    Role:      "user",
    Content:   "请转录这段音频",
    AudioURL:  "https://example.com/audio.wav",
}
```

### 4. 对话历史

完整的对话历史管理和持久化：

```go
// 创建对话
conversation, err := service.CreateConversation(ctx, "user-123", map[string]interface{}{
    "title": "客服对话",
    "category": "customer_service",
})

// 添加消息
message := &ai.Message{
    Role:    "user",
    Content: "你好，请问有什么可以帮助您的？",
}
err = service.AddMessage(ctx, conversation.ID, message)

// 获取对话历史
conversations, err := service.ListConversations(ctx, "user-123", 20, 0)
```

### 5. 缓存机制

智能缓存减少重复请求：

```go
// 配置缓存
config := ai.DefaultConfig()
config.Cache.Enabled = true
config.Cache.TTL = time.Hour
config.Cache.MaxSize = 1000

// 自动缓存相同请求
// 相同问题的第二次请求会直接返回缓存结果
```

### 6. 中间件系统

支持请求和响应的中间件处理：

```go
// 自定义中间件
type LoggingMiddleware struct{}

func (m *LoggingMiddleware) Process(ctx context.Context, request *ai.ChatRequest, next ai.AIService) (*ai.ChatResponse, error) {
    log.Printf("开始处理请求: %+v", request)
    
    response, err := next.Chat(ctx, request)
    
    log.Printf("请求处理完成: %v, 错误: %v", response != nil, err)
    return response, err
}

// 添加中间件
service.AddMiddleware(&LoggingMiddleware{})
```

### 7. 插件系统

支持功能插件扩展：

```go
// 自定义插件
type ContentFilterPlugin struct{}

func (p *ContentFilterPlugin) Process(ctx context.Context, message *ai.Message) (*ai.Message, error) {
    // 内容过滤逻辑
    if containsSensitiveContent(message.Content) {
        return &ai.Message{
            Role:    "assistant",
            Content: "抱歉，我无法回答这个问题。",
        }, nil
    }
    return message, nil
}

// 添加插件
service.AddPlugin(&ContentFilterPlugin{})
```

## 多提供商支持

### OpenAI
- 支持GPT-3.5、GPT-4系列模型
- 完整的API功能
- 流式响应支持
- 函数调用支持

### Claude (Anthropic)
- 支持Claude系列模型
- 高质量对话能力
- 长上下文支持

### DeepSeek
- 国产AI模型
- 性价比高
- 中文优化

### Qwen (阿里云)
- 通义千问系列
- 多语言支持
- 企业级服务

### Ollama
- 本地模型部署
- 私有数据保护
- 离线使用

## 配置示例

### 基础配置
```yaml
ai:
  enabled: true
  provider: "openai"
  apiKey: "sk-your-api-key-here"
  model: "gpt-3.5-turbo"
  maxTokens: 2048
  temperature: 0.7
  enableStreaming: true
```

### 生产环境配置
```yaml
ai:
  enabled: true
  provider: "openai"
  maxTokens: 4096
  maxRetries: 3
  enableHistory: true
  maxHistoryLength: 50
  
  # 成本控制
  enableCostLimit: true
  dailyTokenLimit: 100000
  
  # 缓存配置
  cache:
    enabled: true
    ttl: 2h
    maxSize: 5000
  
  # 监控配置
  metrics:
    enabled: true
    prefix: "prod_ai"
    tags: ["production", "ai"]
```

### 本地Ollama配置
```yaml
ai:
  enabled: true
  provider: "ollama"
  model: "llama2"
  
  ollama:
    host: "localhost"
    port: 11434
    keepAlive: true
    numPredict: 128
    numCtx: 2048
    repeatPenalty: 1.1
```

## 性能优化

### 1. 并发控制
```go
config := ai.DefaultConfig()
config.MaxConcurrentRequests = 10
config.RequestTimeout = time.Second * 60
```

### 2. 缓存策略
- 相同问题缓存：相同用户相同问题短期缓存
- 模型结果缓存：复杂推理结果长期缓存
- 分层缓存：热问题永久缓存，常规问题短期缓存

### 3. 连接池
```go
// HTTP连接池
client := &http.Client{
    Timeout: time.Second * 30,
    Transport: &http.Transport{
        MaxIdleConns:        100,
        MaxIdleConnsPerHost: 10,
        IdleConnTimeout:     time.Second * 90,
    },
}
```

## 安全考虑

### 1. API密钥管理
- 支持环境变量存储
- 支持配置文件加密
- 支持密钥轮换

### 2. 内容过滤
- 输入内容过滤
- 输出内容检查
- 敏感词检测

### 3. 访问控制
- 用户认证集成
- 权限验证
- 使用量限制

## 监控和运维

### 1. 指标收集
```go
// 请求量指标
requestCounter := metrics.Counter("ai_requests_total", map[string]string{
    "provider": "openai",
    "model": "gpt-3.5-turbo",
})

// 响应时间指标
responseTimer := metrics.Timer("ai_response_duration_seconds", map[string]string{
    "provider": "openai",
})

// 成本指标
costGauge := metrics.Gauge("ai_daily_cost_usd", map[string]string{
    "provider": "openai",
})
```

### 2. 健康检查
```go
// 服务健康检查
if !service.IsReady() {
    return fmt.Errorf("AI service not ready")
}

// 提供商健康检查
err := provider.HealthCheck(ctx)
if err != nil {
    return fmt.Errorf("provider unhealthy: %w", err)
}
```

### 3. 日志记录
- 结构化日志输出
- 不同级别的日志
- 请求链路追踪
- 错误详情记录

## 错误处理

### 1. 错误分类
- **认证错误**: API密钥无效、权限不足
- **请求错误**: 参数错误、模型不存在
- **网络错误**: 连接超时、服务不可用
- **业务错误**: 内容被拒绝、使用量超限

### 2. 重试机制
```go
// 指数退避重试
for attempt := 0; attempt <= maxRetries; attempt++ {
    err := doRequest()
    if err == nil {
        return nil
    }
    
    if isRetryableError(err) {
        time.Sleep(time.Duration(math.Pow(2, float64(attempt))) * time.Second)
        continue
    }
    
    return err
}
```

### 3. 熔断机制
- 错误率超过阈值时暂停请求
- 提供降级服务
- 自动恢复机制

## 测试策略

### 1. 单元测试覆盖
- ✅ 配置验证和默认值
- ✅ 服务创建和初始化
- ✅ 对话管理和消息处理
- ✅ 提供商实现和验证
- ✅ 缓存功能和统计
- ✅ 数据结构和类型转换

### 2. 集成测试
- 端到端对话流程测试
- 多提供商切换测试
- 并发请求处理测试
- 错误恢复和重试测试

### 3. 性能测试
```go
func BenchmarkChatRequest(b *testing.B) {
    service := setupTestService()
    ctx := context.Background()
    
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        request := createTestRequest()
        _, err := service.Chat(ctx, request)
        if err != nil {
            b.Fatal(err)
        }
    }
}
```

## 部署建议

### 1. 环境配置
- 开发环境使用本地模型或测试API
- 测试环境使用独立API密钥
- 生产环境使用高可用配置

### 2. 容器化部署
```dockerfile
FROM golang:1.24-alpine AS builder
WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN go build -o ai-service ./cmd/server

FROM alpine:latest
RUN apk --no-cache add ca-certificates
WORKDIR /root/
COPY --from=builder /app/ai-service .
EXPOSE 8080
CMD ["./ai-service"]
```

### 3. 高可用部署
- 多实例部署
- 负载均衡
- 数据库主从复制
- 缓存集群

## 扩展开发

### 1. 新增提供商
```go
// 实现AIProvider接口
type CustomProvider struct{}

func (p *CustomProvider) Initialize(config *Config) error {
    // 初始化自定义提供商
}

func (p *CustomProvider) Chat(ctx context.Context, request *ChatRequest) (*ChatResponse, error) {
    // 实现聊天逻辑
}

// 注册提供商
func init() {
    ai.RegisterProvider("custom", NewCustomProvider)
}
```

### 2. 自定义中间件
```go
type AuthMiddleware struct{}

func (m *AuthMiddleware) Process(ctx context.Context, request *ai.ChatRequest, next ai.AIService) (*ai.ChatResponse, error) {
    // 身份验证
    if !authenticate(request.UserID) {
        return nil, fmt.Errorf("unauthorized")
    }
    
    return next.Chat(ctx, request)
}
```

### 3. 功能插件
```go
type TranslationPlugin struct{}

func (p *TranslationPlugin) Process(ctx context.Context, message *ai.Message) (*ai.Message, error) {
    // 检测是否需要翻译
    if needsTranslation(message.Content) {
        translated, err := translate(message.Content)
        if err != nil {
            return nil, err
        }
        
        message.Content = translated
        message.Metadata["translated"] = "true"
    }
    
    return message, nil
}
```

## 总结

AI对话插件提供了完整的智能对话解决方案：

1. **多提供商支持**: 支持OpenAI、Claude、DeepSeek、Qwen、Ollama等主流AI服务
2. **丰富的功能**: 流式响应、函数调用、多模态输入、对话历史管理
3. **高性能**: 智能缓存、并发控制、连接池管理
4. **高可用**: 重试机制、熔断保护、故障转移
5. **可扩展**: 中间件系统、插件机制、提供商接口
6. **生产就绪**: 监控告警、安全防护、成本控制

该实现参考了xiaozhi-server-go的架构设计，提供了企业级的AI对话集成能力，可以满足各种业务场景的需求。